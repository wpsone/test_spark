//package com.wps.washdatas;
//
//import org.apache.hadoop.conf.Configuration;
//import org.apache.hadoop.conf.Configured;
//import org.apache.hadoop.fs.Path;
//import org.apache.hadoop.io.NullWritable;
//import org.apache.hadoop.io.Text;
//import org.apache.hadoop.mapreduce.Job;
//import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
//import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
//import org.apache.hadoop.util.Tool;
//import org.apache.hadoop.util.ToolRunner;
//
//public class VideoMain extends Configured implements Tool {
//    @Override
//    public int run(String[] args) throws Exception {
//        Job job = Job.getInstance(super.getConf(), "washDatas");
//        job.setJarByClass(VideoMain.class);
//        job.setInputFormatClass(TextInputFormat.class);
//        TextInputFormat.addInputPath(job,new Path(args[0]));
//        job.setMapperClass(VideoMapper.class);
//        job.setMapOutputKeyClass(Text.class);
//        job.setMapOutputValueClass(NullWritable.class);
//        job.setOutputFormatClass(TextOutputFormat.class);
//        TextOutputFormat.setOutputPath(job,new Path(args[1]));
//        //注意，我们这里没有自定义reducer，会使用默认的一个reducer类
//        job.setNumReduceTasks(7);
//        boolean b = job.waitForCompletion(true);
//        return b?0:1;
//    }
//
//    public static void main(String[] args) throws Exception {
//        int run = ToolRunner.run(new Configuration(), new VideoMain(), args);
//        System.exit(run);
//    }
//}
